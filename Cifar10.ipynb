{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Cifar10.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNgNf9KfwcL3hfMZb6T0NzE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Gy1b7WzIFyIH","colab_type":"text"},"source":["# **Train data on the Cifar10 dataset using Traffic Sign Classifier**"]},{"cell_type":"code","metadata":{"id":"oiLhTlQKAVEP","colab_type":"code","outputId":"9edacd34-37ae-4dce-f351-962704fffd9a","executionInfo":{"status":"ok","timestamp":1590549379730,"user_tz":240,"elapsed":2622,"user":{"displayName":"旷野","photoUrl":"","userId":"08344000465204192735"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["%tensorflow_version 1.x\n","from keras.datasets import cifar10\n","(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n","# y_train.shape is 2d, (50000, 1). While Keras is smart enough to handle this\n","# it's a good idea to flatten the array.\n","y_train = y_train.reshape(-1)\n","y_test = y_test.reshape(-1)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n"],"name":"stdout"},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"thPmPh17Amxx","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import train_test_split\n","X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.3, random_state=42, stratify = y_train)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nlM6n2DzFk5_","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","\n","EPOCHS = 10\n","BATCH_SIZE = 128"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PV6eM8rpFl3_","colab_type":"code","colab":{}},"source":["from tensorflow.contrib.layers import flatten\n","\n","def LeNet(x):    \n","    # Arguments used for tf.truncated_normal, randomly defines variables for the weights and biases for each layer\n","    mu = 0\n","    sigma = 0.1\n","    \n","    # Layer 1: Convolutional. Input = 32x32x3. Output = 28x28x6.\n","    F_W1 = tf.Variable(tf.truncated_normal([5, 5, 3, 6], mean=mu, stddev=sigma))\n","    F_b1 = tf.Variable(tf.zeros(6))   \n","    strides1 = [1, 1, 1, 1]\n","    padding = 'VALID'\n","    Conv1 = tf.nn.conv2d(x, F_W1, strides1, padding) + F_b1\n","\n","    # TODO: Activation.\n","    Conv1 = tf.nn.relu(Conv1)\n","\n","    # TODO: Pooling. Input = 28x28x6. Output = 14x14x6.\n","    Conv1 = tf.nn.max_pool(\n","        Conv1,\n","        ksize=[1, 2, 2, 1],\n","        strides=[1, 2, 2, 1],\n","        padding='VALID')\n","    Conv1 = tf.nn.dropout(Conv1, keep_prob)\n","    \n","    # TODO: Layer 2: Convolutional. Output = 10x10x16.\n","    F_W2 = tf.Variable(tf.truncated_normal([5, 5, 6, 16], mean=mu, stddev=sigma))\n","    F_b2 = tf.Variable(tf.zeros(16))   \n","    strides2 = [1, 1, 1, 1]\n","    padding = 'VALID'\n","    Conv2 = tf.nn.conv2d(Conv1, F_W2, strides2, padding) + F_b2\n","    \n","    # TODO: Activation.\n","    Conv2 = tf.nn.relu(Conv2)\n","\n","    # TODO: Pooling. Input = 10x10x16. Output = 5x5x16.\n","    Conv2 = tf.nn.max_pool(\n","        Conv2,\n","        ksize=[1, 2, 2, 1],\n","        strides=[1, 2, 2, 1],\n","        padding='VALID')\n","    Conv2 = tf.nn.dropout(Conv2, keep_prob)\n","\n","    # TODO: Flatten. Input = 5x5x16. Output = 400.\n","    flat = flatten(Conv2)\n","    \n","    # TODO: Layer 3: Fully Connected. Input = 400. Output = 120.\n","    F_W3 = tf.Variable(tf.truncated_normal([400, 120], mean=mu, stddev=sigma))\n","    F_b3 = tf.Variable(tf.zeros(120))\n","    FC3 = tf.matmul(flat, F_W3) + F_b3\n","\n","    # TODO: Activation.\n","    FC3 = tf.nn.relu(FC3)\n","    FC3 = tf.nn.dropout(FC3, keep_prob)\n","\n","    # TODO: Layer 4: Fully Connected. Input = 120. Output = 84.\n","    F_W4 = tf.Variable(tf.truncated_normal([120, 84], mean=mu, stddev=sigma))\n","    F_b4 = tf.Variable(tf.zeros(84))\n","    FC4 = tf.matmul(FC3, F_W4) + F_b4\n","    \n","    # TODO: Activation.\n","    FC4 = tf.nn.relu(FC4)\n","    FC4 = tf.nn.dropout(FC4, keep_prob)\n","\n","    # TODO: Layer 5: Fully Connected. Input = 84. Output = 43.\n","    F_W5 = tf.Variable(tf.truncated_normal([84, 43], mean=mu, stddev=sigma))\n","    F_b5 = tf.Variable(tf.zeros(43))\n","    logits = tf.matmul(FC4, F_W5) + F_b5\n","    \n","    return logits"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uMU6tKoHGGnx","colab_type":"code","colab":{}},"source":["### Train your model here.\n","### Calculate and report the accuracy on the training and validation set.\n","### Once a final model architecture is selected, \n","### the accuracy on the test set should be calculated and reported as well.\n","### Feel free to use as many code cells as needed.\n","\n","# Placeholders\n","x = tf.placeholder(tf.float32, (None, 32, 32, 3))\n","y = tf.placeholder(tf.int32, (None))\n","keep_prob = tf.placeholder(tf.float32)\n","one_hot_y = tf.one_hot(y, 43)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0J1FZg2iGH1E","colab_type":"code","outputId":"49b7c4a7-a73c-474d-b80d-9b77330e6dae","executionInfo":{"status":"ok","timestamp":1590549407148,"user_tz":240,"elapsed":1676,"user":{"displayName":"旷野","photoUrl":"","userId":"08344000465204192735"}},"colab":{"base_uri":"https://localhost:8080/","height":326}},"source":["# Training Pipeline\n","\n","rate = 0.001\n","\n","logits = LeNet(x)\n","cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = one_hot_y)\n","loss_operation = tf.reduce_mean(cross_entropy)\n","optimizer = tf.train.AdamOptimizer(learning_rate = rate)\n","training_operation = optimizer.minimize(loss_operation)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-4-6dbdfef99b35>:24: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.flatten instead.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/layers/core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","WARNING:tensorflow:From <ipython-input-6-ad50ef28f55c>:6: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","\n","Future major versions of TensorFlow will allow gradients to flow\n","into the labels input on backprop by default.\n","\n","See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"o8suUx5QGoUW","colab_type":"code","colab":{}},"source":["# Model Evaluation\n","prediction = tf.argmax(logits, 1)\n","correct_prediction = tf.equal(prediction, tf.argmax(one_hot_y, 1))\n","accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n","saver = tf.train.Saver()\n","\n","def evaluate(X_data, y_data):\n","    num_examples = len(X_data)\n","    total_accuracy = 0\n","    sess = tf.get_default_session()\n","    for offset in range(0, num_examples, BATCH_SIZE):\n","        batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n","        accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y, keep_prob: 1.0})\n","        total_accuracy += (accuracy * len(batch_x))\n","    return total_accuracy / num_examples"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xC1GpjV7GpC2","colab_type":"code","outputId":"3dfd32e0-2391-43d8-849d-6284b5211d2d","executionInfo":{"status":"ok","timestamp":1590549437199,"user_tz":240,"elapsed":24192,"user":{"displayName":"旷野","photoUrl":"","userId":"08344000465204192735"}},"colab":{"base_uri":"https://localhost:8080/","height":578}},"source":["# Train the model\n","from sklearn.utils import shuffle\n","with tf.Session() as sess:\n","    sess.run(tf.global_variables_initializer())\n","    num_examples = len(X_train)\n","    \n","    print(\"Training...\")\n","    print()\n","    for i in range(EPOCHS):\n","        X_train, y_train = shuffle(X_train, y_train)\n","        for offset in range(0, num_examples, BATCH_SIZE):\n","            end = offset + BATCH_SIZE\n","            batch_x, batch_y = X_train[offset:end], y_train[offset:end]\n","            sess.run(training_operation, feed_dict={x: batch_x, y: batch_y, keep_prob: 0.9})\n","            \n","        validation_accuracy = evaluate(X_valid, y_valid)\n","        print(\"EPOCH {} ...\".format(i+1))\n","        print(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n","        print()\n","        \n","    saver.save(sess, './Cifar10')\n","    print(\"Model saved\")"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Training...\n","\n","EPOCH 1 ...\n","Validation Accuracy = 0.249\n","\n","EPOCH 2 ...\n","Validation Accuracy = 0.324\n","\n","EPOCH 3 ...\n","Validation Accuracy = 0.381\n","\n","EPOCH 4 ...\n","Validation Accuracy = 0.408\n","\n","EPOCH 5 ...\n","Validation Accuracy = 0.421\n","\n","EPOCH 6 ...\n","Validation Accuracy = 0.438\n","\n","EPOCH 7 ...\n","Validation Accuracy = 0.451\n","\n","EPOCH 8 ...\n","Validation Accuracy = 0.450\n","\n","EPOCH 9 ...\n","Validation Accuracy = 0.463\n","\n","EPOCH 10 ...\n","Validation Accuracy = 0.475\n","\n","Model saved\n"],"name":"stdout"}]}]}